#!/usr/bin/env python3
"""
æµ‹è¯•å¾®ä¿¡çˆ¬è™«çš„å¢é‡çˆ¬å–åŠŸèƒ½
"""

import os
import sys
import json
import sqlite3
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from modules.storage import DataStorage

class TestIncrementalCrawling:
    """æµ‹è¯•å¢é‡çˆ¬å–åŠŸèƒ½"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•"""
        # ä½¿ç”¨æµ‹è¯•æ•°æ®åº“
        self.test_db_path = os.path.join('data', 'db', 'wechat_test.db')
        self.test_db_path = os.path.abspath(self.test_db_path)
        
        # ç¡®ä¿æµ‹è¯•æ•°æ®åº“ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(self.test_db_path), exist_ok=True)
        
        # åˆ é™¤æ—§çš„æµ‹è¯•æ•°æ®åº“
        if os.path.exists(self.test_db_path):
            os.remove(self.test_db_path)
        
        # åˆ›å»ºå­˜å‚¨å®ä¾‹
        self.storage = DataStorage(self.test_db_path)
        print(f"æµ‹è¯•æ•°æ®åº“: {self.test_db_path}")
        print("=" * 80)
    
    def create_test_article(self, title, url, publish_time):
        """åˆ›å»ºæµ‹è¯•æ–‡ç« """
        return {
            'title': title,
            'url': url,
            'account_name': 'æµ‹è¯•å…¬ä¼—å·',
            'publish_time': publish_time,
            'content': f"è¿™æ˜¯{title}çš„å†…å®¹",
            'cover_image': 'https://example.com/cover.jpg',
            'crawl_time': datetime.now().isoformat()
        }
    
    def test_first_crawl(self):
        """æµ‹è¯•é¦–æ¬¡çˆ¬å–"""
        print("\næµ‹è¯•åœºæ™¯1: é¦–æ¬¡çˆ¬å–")
        print("-" * 60)
        
        # åˆ›å»ºæµ‹è¯•æ–‡ç« 
        test_articles = []
        base_time = datetime.now()
        
        for i in range(5):
            publish_time = (base_time - timedelta(days=i)).strftime('%Y-%m-%d %H:%M:%S')
            article = self.create_test_article(
                f"æµ‹è¯•æ–‡ç« {i+1}",
                f"https://example.com/article{i+1}",
                publish_time
            )
            test_articles.append(article)
        
        # ä¿å­˜æ–‡ç« 
        for article in test_articles:
            self.storage.save_article(article)
            print(f"ä¿å­˜æ–‡ç« : {article['title']} ({article['publish_time']})")
        
        # éªŒè¯ä¿å­˜ç»“æœ
        all_articles = self.storage.get_all_articles()
        print(f"\næ•°æ®åº“ä¸­æ–‡ç« æ€»æ•°: {len(all_articles)}")
        assert len(all_articles) == 5, f"é¢„æœŸ5ç¯‡æ–‡ç« ï¼Œå®é™…{len(all_articles)}ç¯‡"
        
        # éªŒè¯æœ€æ–°æ–‡ç« 
        latest_article = self.storage.get_latest_article_by_account('æµ‹è¯•å…¬ä¼—å·')
        print(f"æœ€æ–°æ–‡ç« : {latest_article['title']} ({latest_article['publish_time']})")
        assert latest_article['title'] == 'æµ‹è¯•æ–‡ç« 1', f"é¢„æœŸæœ€æ–°æ–‡ç« æ˜¯æµ‹è¯•æ–‡ç« 1"
        
        print("âœ“ é¦–æ¬¡çˆ¬å–æµ‹è¯•é€šè¿‡ï¼")
    
    def test_incremental_crawl(self):
        """æµ‹è¯•å¢é‡çˆ¬å–"""
        print("\næµ‹è¯•åœºæ™¯2: å¢é‡çˆ¬å–")
        print("-" * 60)
        
        # æ¨¡æ‹Ÿå·²æœ‰æ–‡ç« ï¼ˆæ¥è‡ªé¦–æ¬¡çˆ¬å–ï¼‰
        existing_count = len(self.storage.get_all_articles())
        print(f"çˆ¬å–å‰æ•°æ®åº“ä¸­æ–‡ç« æ•°: {existing_count}")
        
        # åˆ›å»ºæ–°æ–‡ç« ï¼ˆæ¯”ç°æœ‰æ–‡ç« æ›´æ–°ï¼‰
        new_article = self.create_test_article(
            "æ–°æµ‹è¯•æ–‡ç« ",
            "https://example.com/new_article",
            (datetime.now() + timedelta(days=1)).strftime('%Y-%m-%d %H:%M:%S')  # æœªæ¥æ—¶é—´
        )
        
        # åˆ›å»ºé‡å¤æ–‡ç« ï¼ˆURLç›¸åŒï¼‰
        duplicate_article = self.create_test_article(
            "é‡å¤æµ‹è¯•æ–‡ç« ",
            "https://example.com/article1",  # ä¸ç°æœ‰æ–‡ç« URLç›¸åŒ
            datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        )
        
        # ä¿å­˜æ–°æ–‡ç« 
        self.storage.save_article(new_article)
        print(f"ä¿å­˜æ–°æ–‡ç« : {new_article['title']}")
        
        # å°è¯•ä¿å­˜é‡å¤æ–‡ç« 
        self.storage.save_article(duplicate_article)
        print(f"å°è¯•ä¿å­˜é‡å¤æ–‡ç« : {duplicate_article['title']}")
        
        # éªŒè¯ç»“æœ
        final_count = len(self.storage.get_all_articles())
        print(f"çˆ¬å–åæ•°æ®åº“ä¸­æ–‡ç« æ•°: {final_count}")
        assert final_count == existing_count + 1, f"é¢„æœŸæ–°å¢1ç¯‡æ–‡ç« ï¼Œå®é™…æ–°å¢{final_count - existing_count}ç¯‡"
        
        # éªŒè¯é‡å¤æ–‡ç« æ˜¯å¦è¢«æ­£ç¡®å¤„ç†
        article_by_url = self.storage.get_article_by_url("https://example.com/article1")
        print(f"é‡å¤URLçš„æ–‡ç« æ ‡é¢˜: {article_by_url['title']}")
        assert article_by_url['title'] == 'æµ‹è¯•æ–‡ç« 1', f"é¢„æœŸæ ‡é¢˜ä¸å˜"
        
        print("âœ“ å¢é‡çˆ¬å–æµ‹è¯•é€šè¿‡ï¼")
    
    def test_article_update(self):
        """æµ‹è¯•æ–‡ç« æ›´æ–°"""
        print("\næµ‹è¯•åœºæ™¯3: æ–‡ç« æ›´æ–°")
        print("-" * 60)
        
        # è·å–ç°æœ‰æ–‡ç« 
        existing_article = self.storage.get_article_by_url("https://example.com/article1")
        print(f"æ›´æ–°å‰æ–‡ç« æ ‡é¢˜: {existing_article['title']}")
        print(f"æ›´æ–°å‰æ–‡ç« å†…å®¹: {existing_article['content']}")
        
        # åˆ›å»ºæ›´æ–°çš„æ–‡ç« 
        updated_article = {
            'title': existing_article['title'],
            'url': existing_article['url'],
            'account_name': existing_article['account_name'],
            'publish_time': existing_article['publish_time'],
            'content': f"è¿™æ˜¯{existing_article['title']}çš„æ›´æ–°å†…å®¹",  # æ›´æ–°å†…å®¹
            'cover_image': existing_article['cover_image'],
            'crawl_time': datetime.now().isoformat()
        }
        
        # ä¿å­˜æ›´æ–°
        self.storage.save_article(updated_article)
        print(f"æ›´æ–°æ–‡ç« å†…å®¹")
        
        # éªŒè¯æ›´æ–°ç»“æœ
        updated_db_article = self.storage.get_article_by_url("https://example.com/article1")
        print(f"æ›´æ–°åæ–‡ç« å†…å®¹: {updated_db_article['content']}")
        assert updated_db_article['content'] == updated_article['content'], f"é¢„æœŸå†…å®¹å·²æ›´æ–°"
        
        print("âœ“ æ–‡ç« æ›´æ–°æµ‹è¯•é€šè¿‡ï¼")
    
    def test_article_exists(self):
        """æµ‹è¯•æ–‡ç« å­˜åœ¨æ€§æ£€æŸ¥"""
        print("\næµ‹è¯•åœºæ™¯4: æ–‡ç« å­˜åœ¨æ€§æ£€æŸ¥")
        print("-" * 60)
        
        # æ£€æŸ¥å­˜åœ¨çš„æ–‡ç« 
        exists = self.storage.article_exists("https://example.com/article1")
        print(f"æ£€æŸ¥å­˜åœ¨çš„æ–‡ç« : {'å­˜åœ¨' if exists else 'ä¸å­˜åœ¨'}")
        assert exists, "é¢„æœŸæ–‡ç« å­˜åœ¨"
        
        # æ£€æŸ¥ä¸å­˜åœ¨çš„æ–‡ç« 
        not_exists = self.storage.article_exists("https://example.com/nonexistent")
        print(f"æ£€æŸ¥ä¸å­˜åœ¨çš„æ–‡ç« : {'å­˜åœ¨' if not_exists else 'ä¸å­˜åœ¨'}")
        assert not not_exists, "é¢„æœŸæ–‡ç« ä¸å­˜åœ¨"
        
        print("âœ“ æ–‡ç« å­˜åœ¨æ€§æ£€æŸ¥æµ‹è¯•é€šè¿‡ï¼")
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("å¼€å§‹æµ‹è¯•å¢é‡çˆ¬å–åŠŸèƒ½")
        print("=" * 80)
        
        try:
            self.test_first_crawl()
            self.test_incremental_crawl()
            self.test_article_update()
            self.test_article_exists()
            
            print("\n" + "=" * 80)
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
            print("å¢é‡çˆ¬å–åŠŸèƒ½å·¥ä½œæ­£å¸¸ï¼")
            print("=" * 80)
            
        except Exception as e:
            print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # æ¸…ç†æµ‹è¯•æ•°æ®åº“
            if os.path.exists(self.test_db_path):
                os.remove(self.test_db_path)
                print(f"\næ¸…ç†æµ‹è¯•æ•°æ®åº“: {self.test_db_path}")

if __name__ == "__main__":
    test = TestIncrementalCrawling()
    test.run_all_tests()
