[1mdiff --cc Fed_in_Print.py[m
[1mindex 77f33d5,a9d3f61..0000000[m
[1m--- a/Fed_in_Print.py[m
[1m+++ b/Fed_in_Print.py[m
[36m@@@ -1,142 -1,170 +1,296 @@@[m
  import requests[m
  import csv[m
  import os[m
[32m+ import re[m
[32m+ from dotenv import load_dotenv[m
[32m+ [m
[32m+ # åŠ è½½ç¯å¢ƒå˜é‡[m
[32m+ load_dotenv()[m
  [m
  # --- é…ç½® ---[m
[32m++<<<<<<< HEAD[m
[32m +API_KEY = "2360a68c16b805cf2a02db06372ce22c"[m
[32m +BASE_URL = "https://fedinprint.org/api"[m
[32m +# æ¯é¡µè¯·æ±‚å¤šå°‘æ¡è®°å½•ï¼Œæœ€å¤§å€¼ä¼¼ä¹æ˜¯100[m
[32m +ITEMS_PER_PAGE = 100[m
[32m +[m
[32m +def get_articles(keyword=None):[m
[32m +    """[m
[32m +    ä» Fed in Print API è·å–æ–‡ç« æ•°æ®ã€‚[m
[32m +    å¦‚æœæä¾›äº†å…³é”®è¯ï¼Œåˆ™æŒ‰æ ‡é¢˜æœç´¢ã€‚å¦åˆ™ï¼Œè·å–æ‰€æœ‰æ–‡ç« ã€‚[m
[32m +    """[m
[32m +    if keyword:[m
[32m +        print(f"æ­£åœ¨æœç´¢å…³é”®è¯ä¸º '{keyword}' çš„æ–‡ç« ...")[m
[32m +        endpoint = f"{BASE_URL}/item/search"[m
[32m +        params = {"title": keyword}[m
[32m +    else:[m
[32m +        print("å‡†å¤‡è·å–æ‰€æœ‰æ–‡ç« ...")[m
[32m +        endpoint = f"{BASE_URL}/item"[m
[32m +        params = {}[m
[32m +[m
[32m +    # ä½¿ç”¨ Session å¯ä»¥å¤ç”¨TCPè¿æ¥ï¼Œå¹¶ä¿æŒheaders[m
[32m++=======[m
[32m+ API_KEY = os.getenv("FED_IN_PRINT_API_KEY")[m
[32m+ BASE_URL = "https://fedinprint.org/api"[m
[32m+ ITEMS_PER_PAGE = 100[m
[32m+ [m
[32m+ [m
[32m+ def ask_search_scope() -> int:[m
[32m+     while True:[m
[32m+         choice = input([m
[32m+             "è¯·é€‰æ‹©æœç´¢èŒƒå›´ï¼š\n"[m
[32m+             "0 - æ ‡é¢˜ + æ‘˜è¦\n"[m
[32m+             "1 - ä»…æ ‡é¢˜\n"[m
[32m+             "2 - ä»…æ‘˜è¦\n"[m
[32m+             "è¯·è¾“å…¥ 0 / 1 / 2ï¼š"[m
[32m+         ).strip()[m
[32m+         if choice in {"0", "1", "2"}:[m
[32m+             return int(choice)[m
[32m+         print("è¾“å…¥æ— æ•ˆï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")[m
[32m+ [m
[32m+ [m
[32m+ def extract_year_from_title(title: str) -> str:[m
[32m+     m = re.search(r'\b(19|20)\d{2}\b', title)[m
[32m+     return m.group() if m else "N/A"[m
[32m+ [m
[32m+ [m
[32m+ def build_endpoint_and_params(scope: int, keyword: str):[m
[32m+     if not keyword:[m
[32m+         return f"{BASE_URL}/item", {}[m
[32m+     if scope == 0:[m
[32m+         return f"{BASE_URL}/item/search", {"title": keyword, "abstract": keyword}[m
[32m+     elif scope == 1:[m
[32m+         return f"{BASE_URL}/item/search", {"title": keyword}[m
[32m+     else:  # scope == 2[m
[32m+         return f"{BASE_URL}/item/search", {"abstract": keyword}[m
[32m+ [m
[32m+ [m
[32m+ def get_articles(keyword: str, scope: int):[m
[32m+     # æ£€æŸ¥APIå¯†é’¥[m
[32m+     if not API_KEY or API_KEY == "YOUR_API_KEY_HERE":[m
[32m+         print("é”™è¯¯: è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®FED_IN_PRINT_API_KEYç¯å¢ƒå˜é‡")[m
[32m+         return [][m
[32m+ [m
[32m+     endpoint, params = build_endpoint_and_params(scope, keyword)[m
[32m+     if keyword:[m
[32m+         scope_desc = ["æ ‡é¢˜+æ‘˜è¦", "ä»…æ ‡é¢˜", "ä»…æ‘˜è¦"][scope][m
[32m+         print(f"æ­£åœ¨æœç´¢ {scope_desc} ä¸­åŒ…å«'{keyword}' çš„æ–‡ç« ..")[m
[32m+     else:[m
[32m+         print("å‡†å¤‡è·å–æ‰€æœ‰æ–‡ç« ..")[m
[32m+ [m
[32m++>>>>>>> 0c80f2b00630fd40913e024832ef018e37307d57[m
      session = requests.Session()[m
      session.headers.update({"X-API-Key": API_KEY})[m
  [m
      all_articles = [][m
      page = 1[m
[32m++<<<<<<< HEAD[m
[32m +    [m
[32m++=======[m
[32m++>>>>>>> 0c80f2b00630fd40913e024832ef018e37307d57[m
      while True:[m
          params['limit'] = ITEMS_PER_PAGE[m
          params['page'] = page[m
[31m -[m
[32m +        [m
          try:[m
[32m++<<<<<<< HEAD[m
[32m +            print(f"æ­£åœ¨è·å–ç¬¬ {page} é¡µ...")[m
[32m +            response = session.get(endpoint, params=params, timeout=30)[m
[32m +            # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ[m
[32m +            response.raise_for_status() [m
[32m +            [m
[32m +            data = response.json()[m
[32m +            print(f"APIå“åº”æ•°æ®ç»“æ„: {type(data)}, keys: {list(data.keys()) if isinstance(data, dict) else 'Not a dict'}")[m
[32m++=======[m
[32m+             data = session.get(endpoint, params=params, timeout=30).json()[m
[32m++>>>>>>> 0c80f2b00630fd40913e024832ef018e37307d57[m
              records = data.get("records", [])[m
[31m- [m
              if not records:[m
                  print("æœªæ‰¾åˆ°æ›´å¤šè®°å½•ï¼Œè·å–ç»“æŸã€‚")[m
                  break[m
  [m
[32m++<<<<<<< HEAD[m
[32m +            print(f"Recordsç±»å‹: {type(records)}, é•¿åº¦: {len(records) if isinstance(records, (list, tuple)) else 'N/A'}")[m
[32m +            if records:[m
[32m +                print(f"ç¬¬ä¸€æ¡è®°å½•ç±»å‹: {type(records[0])}")[m
[32m +                if isinstance(records[0], dict):[m
[32m +                    print(f"ç¬¬ä¸€æ¡è®°å½•keys: {list(records[0].keys())}")[m
[32m +[m
[32m +            for record in records:[m
[32m +                # æå–ä½œè€…åå­—å¹¶åˆå¹¶æˆä¸€ä¸ªå­—ç¬¦ä¸²[m
[32m +                # é¦–å…ˆæ£€æŸ¥recordæ˜¯å¦ä¸ºå­—å…¸[m
[32m +                if not isinstance(record, dict):[m
[32m +                    print(f"è­¦å‘Š: recordä¸æ˜¯å­—å…¸ç±»å‹ï¼Œè€Œæ˜¯ {type(record)}ï¼Œå†…å®¹: {record}")[m
[32m +                    # å¦‚æœrecordä¸æ˜¯å­—å…¸ï¼Œè·³è¿‡æ­¤è®°å½•[m
[32m +                    continue[m
[32m +                [m
[32m +                # å¤„ç†authorå­—æ®µå¯èƒ½ä¸ºåˆ—è¡¨æˆ–å­—å…¸çš„æƒ…å†µ[m
[32m +                authors_list = record.get("author", [])[m
[32m +                authors = ""[m
[32m +                if isinstance(authors_list, list):[m
[32m +                    # å¦‚æœauthoræ˜¯åˆ—è¡¨ï¼Œéå†æ¯ä¸ªå…ƒç´ è·å–åå­—[m
[32m +                    authors = ", ".join([author.get("name", "") if isinstance(author, dict) else str(author) for author in authors_list])[m
[32m +                elif isinstance(authors_list, dict):[m
[32m +                    # å¦‚æœauthoræ˜¯å­—å…¸ï¼Œç›´æ¥è·å–åå­—[m
[32m +                    authors = authors_list.get("name", "")[m
[32m +                else:[m
[32m +                    # å…¶ä»–æƒ…å†µï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²[m
[32m +                    authors = str(authors_list)[m
[32m +                [m
[32m +                # æå–ç¬¬ä¸€ä¸ªå¯ç”¨çš„æ–‡ä»¶é“¾æ¥[m
[32m +                file_url = ""[m
[32m +                if record.get("file"):[m
[32m +                    if isinstance(record["file"], list) and len(record["file"]) > 0:[m
[32m +                        file_url = record["file"][0].get("fileurl", "")[m
[32m +                    else:[m
[32m +                        file_url = str(record["file"]) if "file" in record else ""[m
[32m +[m
[32m +                all_articles.append({[m
[32m +                    "title": record.get("title", "N/A"),[m
[32m +                    "authors": authors,[m
[32m +                    "publication_date": record.get("publicationDate", "N/A"), # æ³¨æ„APIè¿”å›çš„å­—æ®µå¯èƒ½æ˜¯publicationDate[m
[32m +                    "abstract": record.get("abstract", "N/A"),[m
[32m +                    "url": file_url,[m
[32m +                    "id": record.get("id", "N/A")[m
[32m +                })[m
[32m +            [m
[32m +            page += 1[m
[32m +[m
[32m +        except requests.exceptions.HTTPError as e:[m
[32m +            print(f"HTTP é”™è¯¯: {e}")[m
[32m +            print(f"æœåŠ¡å™¨è¿”å›å†…å®¹: {response.text}")[m
[32m +            break[m
[32m +        except requests.exceptions.RequestException as e:[m
[32m +            print(f"è¯·æ±‚å‘ç”Ÿé”™è¯¯: {e}")[m
[32m +            break[m
[32m +        except ValueError: # JSONDecodeError[m
[32m +            print(f"æ— æ³•è§£æè¿”å›çš„ JSON æ•°æ®ã€‚")[m
[32m +            print(f"æœåŠ¡å™¨è¿”å›å†…å®¹: {response.text}")[m
[32m +            break[m
[32m++=======[m
[32m+             for rec in records:[m
[32m+                 if not isinstance(rec, dict):[m
[32m+                     continue[m
[32m+ [m
[32m+                 authors_data = rec.get("author", [])[m
[32m+                 if isinstance(authors_data, list):[m
[32m+                     authors = ", ".join([m
[32m+                         a.get("name", "Unknown") if isinstance(a, dict) else str(a)[m
[32m+                         for a in authors_data[m
[32m+                     )[m
[32m+                 else:[m
[32m+                     authors = str(authors_data) if authors_data else "N/A"[m
[32m+ [m
[32m+                 file_url = ""[m
[32m+                 if isinstance(rec.get("file"), list) and rec["file"]:[m
[32m+                     file_url = ([m
[32m+                         rec["file"][0].get("fileurl", "")[m
[32m+                         if isinstance(rec["file"][0], dict)[m
[32m+                         else ""[m
[32m+                     )[m
[32m+ [m
[32m+                 pub_date = rec.get("publication_date") or rec.get("publicationDate")[m
[32m+                 year = pub_date if pub_date else extract_year_from_title(rec.get("title", ""))[m
[32m+ [m
[32m+                 article_data = {[m
[32m+                     "title": rec.get("title", "N/A"),[m
[32m+                     "authors": authors,[m
[32m+                     "year": year,[m
[32m+                     "pages": rec.get("pages", "N/A"),[m
[32m+                     "url": file_url,[m
[32m+                     "id": rec.get("id", "N/A"),[m
[32m+                     "abstract": rec.get("abstract", "N/A"),[m
[32m+                 }[m
[32m+ [m
[32m+                 # è¿‡æ»¤é€»è¾‘[m
[32m+                 if keyword:[m
[32m+                     title_lower = article_data["title"].lower()[m
[32m+                     abstract_lower = article_data["abstract"].lower()[m
[32m+                     kw_lower = keyword.lower()[m
  [m
[32m+                     if scope == 0 and (kw_lower in title_lower or kw_lower in abstract_lower):[m
[32m+                         all_articles.append(article_data)[m
[32m+                     elif scope == 1 and kw_lower in title_lower:[m
[32m+                         all_articles.append(article_data)[m
[32m+                     elif scope == 2 and kw_lower in abstract_lower:[m
[32m+                         all_articles.append(article_data)[m
[32m+                 else:[m
[32m+                     all_articles.append(article_data)[m
[32m++>>>>>>> 0c80f2b00630fd40913e024832ef018e37307d57[m
[32m+ [m
[32m+             page += 1[m
[32m+         except Exception as e:[m
[32m+             print("è¯·æ±‚å‡ºé”™:", e)[m
[32m+             break[m
      return all_articles[m
  [m
[31m -[m
  def save_to_csv(articles, filename):[m
[32m +    """å°†æ–‡ç« åˆ—è¡¨ä¿å­˜åˆ° CSV æ–‡ä»¶ã€‚"""[m
      if not articles:[m
          print("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–‡ç« ï¼Œæ— éœ€åˆ›å»ºæ–‡ä»¶ã€‚")[m
          return[m
[31m- [m
      try:[m
[32m++<<<<<<< HEAD[m
[32m +        # å®šä¹‰CSVæ–‡ä»¶çš„è¡¨å¤´[m
[32m +        fieldnames = ["title", "authors", "publication_date", "abstract", "url", "id"][m
[32m +        [m
[32m +        with open(filename, "w", newline="", encoding="utf-8") as csvfile:[m
[32m +            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)[m
[32m +            writer.writeheader()[m
[32m +            writer.writerows(articles)[m
[32m +        print(f"\næˆåŠŸ! {len(articles)} ç¯‡æ–‡ç« å·²ä¿å­˜åˆ°æ–‡ä»¶: {os.path.abspath(filename)}")[m
[32m +[m
[32m +    except IOError as e:[m
[32m +        print(f"å†™å…¥æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")[m
[32m +[m
[32m +if __name__ == "__main__":[m
[32m +    # 1. è·å–ç”¨æˆ·è¾“å…¥[m
[32m +    search_keyword = input("è¯·è¾“å…¥æœç´¢å…³é”®è¯ (ç›´æ¥æŒ‰ Enter è·å–æ‰€æœ‰æ–‡ç« ): ").strip()[m
[32m +[m
[32m +    # 2. è°ƒç”¨å‡½æ•°è·å–æ•°æ®[m
[32m +    articles_found = get_articles(search_keyword if search_keyword else None)[m
[32m +[m
[32m +    # 3. å°†ç»“æœä¿å­˜åˆ°æ–‡ä»¶[m
[32m +    if articles_found:[m
[32m +        if search_keyword:[m
[32m +            output_filename = f"fed_articles_{search_keyword.replace(' ', '_')}.csv"[m
[32m +        else:[m
[32m +            output_filename = "fed_articles_all.csv"[m
[32m +        save_to_csv(articles_found, output_filename)[m
[32m++=======[m
[32m+         # ç°åœ¨æŠŠ abstract æ­£å¼åŠ è¿› CSV[m
[32m+         fieldnames = ["title", "authors", "year", "pages", "url", "id", "abstract"][m
[32m+         with open(filename, "w", newline="", encoding="utf-8-sig") as f:[m
[32m+             writer = csv.DictWriter(f, fieldnames=fieldnames)[m
[32m+             writer.writeheader()[m
[32m+             writer.writerows(articles)[m
[32m+         print(f"\næˆåŠŸ! {len(articles)} æ¡è®°å½•å·²ä¿å­˜åˆ° {os.path.abspath(filename)}")[m
[32m+     except IOError as e:[m
[32m+         print("å†™å…¥æ–‡ä»¶æ—¶å‘ç”Ÿ I/O é”™è¯¯:", e)[m
[32m+ [m
[32m+ [m
[32m+ def display_articles(articles):[m
[32m+     if not articles:[m
[32m+         print("æœªæ‰¾åˆ°ä»»ä½•æ–‡ç« ã€‚")[m
[32m+         return[m
[32m+     print(f"\næ‰¾åˆ° {len(articles)} ç¯‡æ–‡ç« ")[m
[32m+     print("-" * 80)[m
[32m+     for i, art in enumerate(articles, 1):[m
[32m+         print(f"{i}. æ ‡é¢˜  : {art['title']}")[m
[32m+         print(f"   ä½œè€… : {art['authors']}")[m
[32m+         print(f"   å¹´ä»½  : {art['year']}")[m
[32m+         print(f"   é¡µç   : {art['pages']}")[m
[32m+         print(f"   ID    : {art['id']}")[m
[32m+         print(f"   æ‘˜è¦  : {art['abstract'][:300]}{'...' if len(art['abstract']) > 300 else ''}")[m
[32m+         print()[m
[32m+ [m
[32m+ [m
[32m+ if __name__ == "__main__":[m
[32m+     keyword = input("è¯·è¾“å…¥æœç´¢å…³é”®è¯ (ç›´æ¥æŒ‰ Enter è·å–æ‰€æœ‰æ–‡ç« ): ").strip()[m
[32m+     scope = ask_search_scope()[m
[32m+     articles = get_articles(keyword, scope)[m
[32m+     display_articles(articles)[m
[32m+     if articles:[m
[32m+         safe = keyword.replace(' ', '_').replace('/', '_') if keyword else "all"[m
[31m -        save_to_csv(articles, f"fed_articles_{safe}.csv")[m
[32m++        save_to_csv(articles, f"fed_articles_{safe}.csv")[m
[32m++>>>>>>> 0c80f2b00630fd40913e024832ef018e37307d57[m
